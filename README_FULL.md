# BigDataStructure ‚Äì Homework Automations (Schema Parsing, Size Estimation, Sharding & Operators)

This package implements the full set of requirements from the Big Data Structure coursework:
- JSON schema parsing  
- document / collection / database size computation  
- sharding statistics  
- operator-level cost estimation (filter + join)  
- professor‚Äôs cost model (network volume, time, CO‚ÇÇ, price)

The system is completely general:  
it works for any JSONSchema and any set of queries defined in terms of:
- SELECT fields  
- WHERE filter keys  
- sharding key  
- primary key (optional)  
- distinct_values statistics  

---

# üìÅ Project Structure

```
BigDataStructure/
‚îÇ
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ core/models.py              
‚îÇ   ‚îú‚îÄ‚îÄ parsers/json_schema.py       
‚îÇ   ‚îú‚îÄ‚îÄ core/size_calc.py     
‚îÇ   ‚îú‚îÄ‚îÄ sharding_analyzer.py   
‚îÇ   ‚îú‚îÄ‚îÄ cost_model/formulas.py      
‚îÇ   ‚îú‚îÄ‚îÄ cost_model/operations.py           
‚îÇ
‚îú‚îÄ‚îÄ examples/
‚îÇ   ‚îú‚îÄ‚îÄ schema_DB1.json
‚îÇ   ‚îú‚îÄ‚îÄ schema_DB2.json
‚îÇ   ‚îú‚îÄ‚îÄ schema_DB3.json
‚îÇ   ‚îú‚îÄ‚îÄ schema_DB4.json
‚îÇ   ‚îú‚îÄ‚îÄ schema_DB5.json
‚îÇ   ‚îú‚îÄ‚îÄ stats_full.json
‚îÇ   ‚îî‚îÄ‚îÄ test_script_hw3.py     
‚îÇ
‚îî‚îÄ‚îÄ README.md
```

---

# 1. JSON Schema Parsing (`parsers/json_schema.py`)

The parser converts a JSONSchema into internal Python objects (`Collection`, `Field`).  
It supports nested objects, arrays, and custom type sizes (integer, string, longstring, date).

---

# 2. Size Calculation (`core/size_calc.py`)

Document size uses the professor‚Äôs formula:

```
field_size = 12B (overhead) + type_size
```

Collection size and DB size are computed automatically.

---

# 3. Sharding Analysis (`sharding_analyzer.py`)

Computes:

- docs/server  
- keys/server  

Used to evaluate whether a sharding key is well balanced.

---

# 4. Cost Model (`cost_model/formulas.py`)

Implements:

- query size  
- message size  
- network volume  
- time_network  
- time_cpu  
- time_total  
- CO‚ÇÇ and price  

Using the professor‚Äôs constants (100 MB/s, 25 GB/s, etc.).

---

# 5. Operators (`cost_model/operations.py`)

Implements:

- filter_without_sharding  
- filter_with_sharding  
- nested_loop_without_sharding  
- nested_loop_with_sharding  

Each operator returns `CostOutput` containing all cost metrics.

---

# 6. Test Script

Run with:

```
python -m examples.test_script_hw3
```

---

# 7. Usage Example

```python
result = filter_with_sharding(
    coll=collections["Stock"],
    filter_keys=["IDP", "IDW"],
    select_fields=["quantity", "location"],
    sharding_key="IDP",
    distinct_values=stats["distinct_values"],
    servers=stats["servers"],
    pk_fields=["IDP", "IDW"]
)
```

---

# 8. Oral Exam Summary

Explain:

- document size formula  
- sharding effect on S  
- PK lookup meaning (res_q = 1)  
- network volume computation  
- join costs  

---

# 9. Conclusion

This package fully automates HW2 + HW3 and provides a modular framework for evaluating NoSQL performance.

---

# 10. Examples & Detailed Calculations

## 10.1 Field Size Model

```
integer    = 12 + 8  = 20B  
string     = 12 + 80 = 92B  
longstring = 12 + 200 = 212B  
date       = 12 + 20 = 32B
```

---

# 10.2 FILTER WITH SHARDING ‚Äî Example Q1

Query:

```
SELECT quantity, location
FROM Stock
WHERE IDP = X AND IDW = Y
```

### Involved fields:

```
quantity  ‚Üí integer ‚Üí 20B  
location  ‚Üí string  ‚Üí 92B  
IDP       ‚Üí integer ‚Üí 20B  
IDW       ‚Üí integer ‚Üí 20B  
```

### size_query:

```
20 + 92 + 20 + 20 = 152B
```

### size_msg:

```
20 + 92 = 112B
```

### Sharding:

```
sharding_key = IDP
filter_keys include IDP ‚Üí S = 1
```

### Result cardinality:

Stock PK = (IDP, IDW):

```
res_q = 1
```

### Network volume:

```
vol_network = 1 √ó 152 + 1 √ó 112 = 264B
```

---

# 10.3 FILTER WITHOUT SHARDING ‚Äî Example

Query:

```
SELECT IDP, name, brand
FROM Product
WHERE brand = X
```

### size_query:

```
IDP = 20B  
name = 92B  
brand = 92B  
(brand WHERE) = 92B  
----------------------
size_query = 296B
```

### Result estimate:

```
res_q = N(Product)/Ndistinct(brand)
= 100000 / 5000
= 20 docs
```

### Broadcasting to 1000 servers:

```
S = 1000
```

### vol_network:

```
1000 √ó 296 + 20 √ó 204 = 300080B
```

---

# 10.4 NESTED LOOP JOIN WITHOUT SHARDING

Join:

```
Stock ‚ãà Product ON IDP
```

### Cardinality:

```
result_docs = |Stock| √ó |Product| / Ndistinct(IDP)
             = (20M √ó 100k) / 100k
             = 20M
```

### Message size:

```
doc_stock   = 296B
doc_product = 1224B
size_msg    = 1520B
```

### Network volume:

Move smaller relation (Product):

```
Product_bytes = 100k √ó 1224B
vol_network = Product_bytes + result_docs √ó size_msg
```

---

# 10.5 NESTED LOOP JOIN WITH SHARDING

If sharded on IDP:

```
vol_network = result_docs √ó size_msg
```

No relation shipping is required.

---

# 10.6 What Each Function Does

### parse_schema()
Reads JSON schema ‚Üí builds Collection objects with types and subfields.

### doc_size()
Computes byte size of a single document.

### collection_size()
Computes total storage of a collection.

### db_size()
Sums all collections.

### sharding_stats()
Computes docs/server and keys/server.

### filter_with_sharding()
Implements:
- S = 1 if sharding key is in filters  
- result cardinality (PK lookup or selectivity)  
- cost model application  

### filter_without_sharding()
Same as above but:
- S = servers  
- full broadcast  

### nested_loop_without_sharding()
Computes:
- join cardinality  
- movement of smaller relation  
- result shipping cost  

### nested_loop_with_sharding()
Assumes perfect sharding:
- no movement of inputs  
- only result transmission  

---

This expanded section provides step-by-step numerical examples for understanding all internal computations of the system.
